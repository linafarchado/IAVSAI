{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoriel : interagir avec le système de stockage S3 du SSP Cloud (MinIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tiktoken\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer les données d'un challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "# Lister les challenges\n",
    "#fs.ls(\"gvimont/diffusion/hackathon-minarm-2024\")\n",
    "\n",
    "# Lister les fichiers d'un challenge\n",
    "fs.ls(\"civel/diffusion/hackathon-minarm-2024/AIVSAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les données dans le service\n",
    "PATH_IN = 'civel/diffusion/hackathon-minarm-2024/AIVSAI/HC3.zip'\n",
    "fs.download(PATH_IN, 'data/HC3.zip')\n",
    "\n",
    "# Décompresser les données\n",
    "with zipfile.ZipFile(\"data/HC3.zip\",\"r\") as zip_file:\n",
    "    zip_file.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : les données peuvent être également téléchargées directement si besoin, pour être utilisées hors du SSP CLoud.\n",
    "Exemple pour le fichier ci-dessus (même format de lien pour les autres challenges) : \n",
    "\n",
    "http://minio.lab.sspcloud.fr/gvimont/diffusion/hackathon-minarm-2024/AIVSAI/HC3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporter des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_files():\n",
    "    directory = 'data/HC3'\n",
    "\n",
    "    file_path = \"data/HC3/all.jsonl\"\n",
    "    dfs = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    \n",
    "    # Get a list of all .jsonl files in the directory, excluding all.jsonl and reddit_eli5.jsonl\n",
    "    #jsonl_files = [file for file in os.listdir(directory) if file.endswith('.jsonl') and file not in ['all.jsonl']]\n",
    "    \n",
    "    # Add data in dataframe\n",
    "    #dfs = pd.DataFrame()\n",
    "    #for file in jsonl_files:\n",
    "    #    file_path = os.path.join(directory, file)\n",
    "    #    df = pd.read_json(file_path, lines=True)\n",
    "        \n",
    "        # Add a new column with the source file name\n",
    "    #    df['source'] = file[:-6]\n",
    "        \n",
    "        # Concatenate to DataFrame\n",
    "    #    dfs = pd.concat([dfs, df], ignore_index=True)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "df = load_jsonl_files()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_question(question):\n",
    "    # Remove if question starts with 'Q.'\n",
    "    return question[3:].strip() if question[:3] == 'Q. ' else question\n",
    "\n",
    "def clean_questions(df):\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    df_cleaned['question'] = df_cleaned['question'].apply(lambda x: clean_question(x))\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(answer):\n",
    "    # Transform list answer into string\n",
    "    return ' '.join(answer) if isinstance(answer, list) else answer\n",
    "\n",
    "def clean_answers(df):\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    df_cleaned['human_answers'] = df_cleaned['human_answers'].apply(lambda x: clean_answer(x))\n",
    "    df_cleaned['chatgpt_answers'] = df_cleaned['chatgpt_answers'].apply(lambda x: clean_answer(x))\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_type_data(df) :\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned['human_answers'].astype(str)\n",
    "    df_cleaned['chatgpt_answers'].astype(str)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    df = clean_answers(df)\n",
    "    df = df.drop_duplicates()\n",
    "    df = clean_questions(df)\n",
    "    df = clean_type_data(df)\n",
    "    if 'index' in df.columns :\n",
    "        df = df.drop(columns=\"index\")\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export vers un bucket personnel\n",
    "PATH_OUT = 'misterfacile/diffusion/projet-mongroupe-hackathon/all_dataset.csv'\n",
    "with fs.open(PATH_OUT, 'w') as file_out:\n",
    "    df.to_csv(file_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : le dossier 'diffusion' permet un accès en lecture à tous les membres du groupe !\n",
    "# Tous les membres peuvent donc le voir et l'utiliser dans un service\n",
    "fs.ls(\"misterfacile/diffusion/projet-mongroupe-hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(PATH_OUT, mode=\"r\") as file_in:\n",
    "    df_test = pd.read_csv(file_in)\n",
    "    df_test = clean_dataframe(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_doc = \" \".join(df_test['human_answers'].head())\n",
    "whole_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenize(doc: str) -> list[str]:\n",
    "    return word_tokenize(doc)\n",
    "\n",
    "def gpt_tokenize(doc: str) -> list:\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    tokens = enc.encode(doc)\n",
    "    return [str(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc: str, base_tokenizer=word_tokenize, do_lower=False, do_remove_stop_word=False, custom_stop_words=[], do_lemmatize=False) -> tuple[list,list]:\n",
    "    if do_lower:\n",
    "        doc = doc.lower()\n",
    "    list_token = base_tokenizer(doc)\n",
    "\n",
    "    if do_remove_stop_word:\n",
    "        stop_words = en_stop | set(\"-.!?()_;:,'\") | {'...'} | set(custom_stop_words) \n",
    "        list_token = [token for token in list_token if token not in stop_words]\n",
    "        \n",
    "    if do_lemmatize:\n",
    "        wnl = WordNetLemmatizer()\n",
    "        list_token = [wnl.lemmatize(t) for t in list_token]\n",
    "\n",
    "    return list_token\n",
    "\n",
    "def use_tokenizer(tokenizer, base_tokenizer=word_tokenize):\n",
    "    return tokenizer\n",
    "\n",
    "def remove_stop_words(custom_stop_words):\n",
    "    return custom_stop_words\n",
    "\n",
    "def add_stop_words(words, custom_stop_words):\n",
    "    custom_stop_words.extend(words)\n",
    "    return custom_stop_words\n",
    "\n",
    "def lower():\n",
    "    return True\n",
    "\n",
    "def lemmatize():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = []\n",
    "list_token = tokenize(whole_doc, do_lower=True, do_remove_stop_word=True, custom_stop_words=custom_stop_words)\n",
    "vocab = set(list_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = { token : list_token.count(token) for token in vocab }\n",
    "sorted(occ.items(), key = lambda x : x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the length of the answer between human and ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareLengthAnswer(data, category=\"\") :\n",
    "\n",
    "    #Collect the length of the answer\n",
    "    if (category == \"\") :\n",
    "        lengthHumanAnswer = data['human_answers'].apply(len)\n",
    "        lengthChatGPTAnswer = data['chatgpt_answers'].apply(len)\n",
    "    else :\n",
    "        lengthHumanAnswer = data[data['source'] == category]['human_answers'].apply(len)\n",
    "        lengthChatGPTAnswer = data[data['source'] == category]['chatgpt_answers'].apply(len)\n",
    "    \n",
    "    # Display the graphic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengthHumanAnswer, bins=20, alpha=0.5, label='Human Answers')\n",
    "    plt.hist(lengthChatGPTAnswer, bins=20, alpha=0.5, label='ChatGPT Answers')\n",
    "    plt.title('Comparaison de la taille des réponses')\n",
    "    plt.xlabel('Quantité de caractères par réponse')\n",
    "    plt.ylabel('Quantité de réponse')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareLengthAnswer(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = df_test[df_test['source'] == 'wiki_csai']['human_answers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(text):\n",
    "    # Utiliser regex pour détecter la fin des phrases avec plus de précision\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    # Retourner le nombre de phrases, en s'assurant qu'on ne compte pas les éléments vides\n",
    "    return len([sentence for sentence in sentences if sentence.strip()])\n",
    "\n",
    "# Appliquer la fonction de comptage sur les colonnes des réponses et créer de nouvelles colonnes pour les comptes\n",
    "df['human_sentence_count'] = df['human_answers'].apply(count_sentences)\n",
    "df['chatgpt_sentence_count'] = df['chatgpt_answers'].apply(count_sentences)\n",
    "\n",
    "# Grouper par la colonne 'source' et calculer la somme des phrases pour chaque source\n",
    "grouped = df.groupby('source').agg({\n",
    "    'human_sentence_count': 'sum',\n",
    "    'chatgpt_sentence_count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "positions = np.arange(len(grouped['source']))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create bars\n",
    "human_bars = ax.bar(positions - width/2, df_grouped['human_sentence_count'], 0.35, label='Human Sentence Count')\n",
    "chatgpt_bars = ax.bar(positions + width/2, df_grouped['chatgpt_sentence_count'], 0.35, label='ChatGPT Sentence Count')\n",
    "\n",
    "ax.set_xlabel('Source')\n",
    "ax.set_ylabel('Sentence Count')\n",
    "ax.set_title('Sentence Count Comparison by Source')\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(df_grouped['source'])\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
